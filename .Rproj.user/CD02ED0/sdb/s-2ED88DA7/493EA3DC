{
    "contents" : "\n################################################\n#4C specific functions\n################################################\n\n\nsignificant.fragments <- function( p.value, pos, window = 21, FDR = 0.01 ){\n  #correct the nominal p-value for multiple hypothesis testing\n  p.combined <- p.adjust(p.value, method=\"fdr\")\n  #determine the significant windows and select the fragments therein\n  sig.i <- which(p.combined < FDR)\n  if(length(sig.i)>0) {\n\t\tsig.i.start <- sig.i-floor(window/2); sig.i.end <- sig.i+floor(window/2)\n\t\tsig.i <- unique(multi.seq(sig.i.start,sig.i.end))\n\t\tsig.i <- sig.i[sig.i >= 1 & sig.i <= length(pos)]\n\t\tsigFrags <- pos[sig.i]\n\t\treturn(sigFrags)\n  } else {\n    return(NULL)\n  }\n}\n\nrighttailgamma = function(r,k,n) 1 - pgamma(-log(r/(n+1)^k),k,scale=1)\n\nrank.product.p <- function( data, num.exp,method=\"diff\"){\n  if(method==\"diff\") {\n  stats <- data[,2:(num.exp+1)]-data[,(2:(num.exp+1))+num.exp]\n  } else {\n  stats <- data[,2:(num.exp+1)]/data[,(2:(num.exp+1))+num.exp]\n  }\n  rp <- nrow(data)-apply(stats,2,rank)+1\n  rp <- apply(rp,1,prod)\n  p <- righttailgamma(rp,num.exp,length(rp))\n}\n\n\ngetWindowedFrags <- function(x,frags,wSize=21) {\n\n\toutFrags <- ((match(x,frags)-floor(wSize/2))):((match(x,frags)+floor(wSize/2)))\n\toutFrags <- outFrags[outFrags>=1&outFrags<=length(frags)]\n\n\treturn(frags[outFrags])\n\n}\n\n#set a dynamic threshold for the residuals\ngetThreshold <- function(resids,qW=5) {\n\tq75 <- quantile(resids,probs=0.75) #75% quantile of the residuals\n\tqd50 <- diff(quantile(resids,probs=c(0.25,0.75))) #the range between the 25% and 75% quantiles\n\tthreshold <- q75 + qW*qd50\n\treturn(threshold)\n}\n\n\n#these are not \"significant\" frags just above an arbitrary threshold\nthresholdFrags <- function(resids,frags,wSize=21,qW=5) {\n\n\tqMax <- getThreshold(resids=resids,qW=qW)\n\n\tsel.i <- which(resids > qMax)\n  if(length(sel.i)>0) {\n\t\tsel.i.start <- sel.i-floor(wSize/2); sel.i.end <- sel.i+floor(wSize/2)\n\t\tsel.i <- unique(multi.seq(sel.i.start,sel.i.end))\n\t\tsel.i <- sel.i[sel.i >= 1 & sel.i <= length(frags)]\n\t\tselFrags <- frags[sel.i]\n\t\treturn(selFrags)\n\t}else{\n\t\treturn(NULL)\n\t}\n\n\n}\n\n#' Single experiment 4C/Capture C analysis\n#'\n#' @param data list containing the 4C/CapC data in two column format, an additional element num.exp describes the number of experiments\n#' @param vp.pos viewpoint position, this can be a single value or a two values to analyse a viewpoint region\n#' @param wSize number of fragments in a window\n#' @param alphaFDR false-discovery rate threshold\n#' @param qWd threshold for difference from the background\n#' @param qWr threshold for ratio over the background\n#' @param minDist minimal region around the viewpoint to exclude for the significance analysis\n#'\n#' @description Function for identifying interaction peaks above a background distribution. A list containing a 4C/Capture-C dataset is required as input. The viewpoint position is given in the vp.pos argument.\n#'\n#' @return a list containing a matrix with the data and the background model and a vector with the significant fragments\n#' @export\n#'\n#' @examples\n#' data <- readMultiple(f[1:3], vp.pos = 65923803)\n#' res <- combined.analysis(data, num.exp=3, vp.pos = 65923803)\n#'\n#'\n#'\nsingle.analysis <- function(data, vp.pos, wSize = 21, qWd = 1.5, qWr = 1, minDist = 15e3) {\n\n  #create two element vector containing the viewpoint position\n  #if only one viewpoint is given\n  if(length(vp.pos) == 1){\n    vp.pos <- c(vp.pos,vp.pos)\n  }\n  vp.pos <- sort(vp.pos)\n\n\n  db <- get.single.background(data=data[[1]], num.exp = 1, vp.pos=vp.pos)\n  #running mean over the data\n  db[,2] <- caTools::runmean(x=db[,2],k=wSize,endrule=\"mean\")\n  #running mean over the isotonic regression line\n  db[,3] <- caTools::runmean(x=db[,3],k=5,endrule=\"mean\")\n\n  #add a pseudocount to improve the calculations\n  pseudoCount <- non.zero.quantile(x=db[,2],probs=0.05)\n  ratios <- cbind(db[, 1], (db[, 2] + pseudoCount)/(db[,3] + pseudoCount))\n  deltas <- cbind(db[, 1], db[,2]-db[,3])\n\n  #frags <- db[, 1]\n  #distFrags <- frags[abs(frags-vp.pos)>=minDist]\n\n  #select the fragments that are more than minDist from the viewpoint\n  sel.frag <- db[which( (db[,1] < vp.pos[1] & vp.pos[1]-db[,1] > minDist) | (db[,1] > vp.pos[2] & db[,1]-vp.pos[2] > minDist) ),1]\n\n  rTFrags <- thresholdFrags(resids=ratios[,2],frags=ratios[,1],wSize=wSize,qW=qWr)\n  dTFrags <- thresholdFrags(resids=deltas[,2],frags=deltas[,1],wSize=wSize,qW=qWd)\n  peakFrags <- intersect(intersect(rTFrags,dTFrags), sel.frag)\n\n  return(list(dbR=db,ratios=ratios,deltas=deltas,peak=peakFrags, num.exp=1))\n\n}\n\n#' Combined 4C/Capture C analysis\n#'\n#' @param data list containing the 4C/CapC data in two column format, an additional element num.exp describes the number of experiments\n#' @param num.exp number of experiments, used in conjuction with \"data\" and \"multi\" in type, default is 0 which means the number in the data list is used, a different number overwrites the default number\n#' @param vp.pos viewpoint position, this can be a single value or a two values to analyse a viewpoint region\n#' @param wSize number of fragments in a window\n#' @param alphaFDR false-discovery rate threshold\n#' @param qW threshold for absolute difference\n#' @param minDist minimal region around the viewpoint to exclude for the significance analysis\n#'\n#' @description Function for identifying interaction peaks above a background distribution. A list of 4C/Capture-C datasets are required as input. The viewpoint position is given in the vp.pos argument.\n#'\n#' @return a list containing a matrix with the data and the background model and a vector with the significant fragments\n#' @export\n#'\n#' @examples\n#' data <- readMultiple(f[1:3], vp.pos = 65923803)\n#' res <- combined.analysis(data, num.exp=3, vp.pos = 65923803)\n#'\n#'\n#'\ncombined.analysis <- function( data, num.exp = 0, vp.pos, wSize = 21, alphaFDR = 0.1, qWr = 1, minDist = 15e3 ){\n  #set the number of experiments\n  if(num.exp == 0){\n    num.exp = data$num.exp\n\n  }\n\n  #create two element vector containing the viewpoint position\n  #if only one viewpoint is given\n  if(length(vp.pos) == 1){\n    vp.pos <- c(vp.pos,vp.pos)\n  }\n  vp.pos <- sort(vp.pos)\n\n\n\tdb <- combine.experiments(data,num.exp, vp.pos)\n\n\t# make a data.frame where a running mean is already applied to apply all statistics to those data -> stronger (positive) dependency between statistics but less variance\n\n\tdbR <- db\n\t#running mean over the data\n\tdbR[,2:(num.exp+1)] <- apply(db[,2:(num.exp+1)],2,caTools::runmean,k=wSize,endrule=\"mean\")\n\t#running mean over the isotonic regression line (window is 5)\n\tdbR[,2:(num.exp+1)+num.exp] <- apply(db[,2:(num.exp+1)+num.exp],2,caTools::runmean,k=5,endrule=\"mean\")\n\n\t# for the ratios add a small pseudocount to avoid dividing by 0. Calculate the ratios and deltas (diff) on the runmean data\n\n\t#add a small pseudo count so that there will be no divide/0 errors\n\tpseudoCount <- apply(db[,2:(num.exp+1)], 2, non.zero.quantile, probs=0.05)\n\tprint(pseudoCount)\n\tpseudoCount <- sum(pseudoCount)/num.exp\n\t#calculate the ratio of the data with the regression line\n\tratio <- cbind(db[,1],(dbR[,2:(num.exp+1)]+pseudoCount)/(dbR[,(2:(num.exp+1))+num.exp]+pseudoCount))\n\t#calculate the differene between the data and the regression line\n\tdelta <- cbind(db[,1],dbR[,2:(num.exp+1)]-dbR[,(2:(num.exp+1))+num.exp])\n\n\t#determine the per-window p-value using rank products based on the ratio\n\tp.val <- rank.product.p(data = dbR, num.exp = num.exp,method=\"diff\")\n\t#select the significant fragments\n\tsfr <- significant.fragments(p.value = p.val, pos = db[, 1], window = wSize, FDR = alphaFDR)\n\n\t#select the fragments that are more than minDist from the viewpoint\n\tsel.frag <- db[which( (db[,1] < vp.pos[1] & vp.pos[1]-db[,1] > minDist) | (db[,1] > vp.pos[2] & db[,1]-vp.pos[2] > minDist) ),1]\n\tidx <- delta[,1]%in%sel.frag\n\n\t#set a threshold on the minimal delta threshold, this threshold is defined empirically\n\ttfr <- thresholdFrags(resids=apply(ratio[idx,2:(num.exp+1)],1,mean),frags=ratio[idx,1],wSize=wSize,qW=qWr)\n\n\tsfr <- intersect(sfr,tfr)\n\tlist(dbR=dbR, peak=sfr, num.exp = num.exp, p.value=p.val, ratio = apply(ratio[,2:(num.exp+1)],1,mean), sel=sel.frag )\n}\n\n#' Take a result from the combined.analysis function and generate a chromosomal map of the result\n#'\n#' @param data list containing the output of combined.analysis (i.e. 4C data and significant fragments)\n#' @param num.exp number of experiments\n#' @param y.min bottom limit of the plot\n#' @param y.max top limit of the plot\n#'\n#' @return Nothing, a plot is drawn\n#' @export\n#'\n#' @examples\nplot_C <- function(data, num.exp = 0, y.min=0, y.max=3000, ...){\n  if(num.exp == 0){\n    num.exp = data$num.exp\n  }\n  pos <- data$dbR[,1]\n  if(num.exp == 1){\n    y.ave <- data$dbR[,2]\n  }else{\n    y.ave <- apply(data$dbR[,2:(num.exp+1)], 1, median)\n  }\n  plot(pos, y.ave, type='h', col=ifelse(pos%in%data$peak, \"red\", \"grey\"), axes=F, xlab=\"chromosomal position\", ylab=\"4C signal\", ylim=c(y.min,y.max), ... )\n  axis(2, at=c(0,y.max), las=2)\n  at <- seq(200e3*floor(min(pos)/200e3), ceiling(max(pos)/200e3)*200e3, by=200e3)\n  axis(1, at=seq(0,1e9,by=200e3), lab=sprintf(\"%.1f\", seq(0,1e9,by=200e3)/1e6), cex.axis=1.5)\n}\n\n\n#' Combine list of experiments into a matrix with the background model\n#'\n#' @param data list containing the 4C/CapC data in two column format\n#' @param num.exp number of experiments, default is 0, which means the the number in the data list is taken, other values allow for choosing a subset of the experiments\n#' @param vp.pos position of the viewpoint\n#'\n#' @return merged matrix containing: 1. the position of the fragments, 2:(n+1) the data, (n+1):(n+n+1) background models corresponding to the respective datasets\n#' @export\n#'\n#' @examples\ncombine.experiments <- function( data, num.exp = 0, vp.pos ){\n  if(num.exp == 0){\n    num.exp = data$num.exp\n  }\n  #create two element vector containing the viewpoint position\n  #if only one viewpoint is given\n  if(length(vp.pos) == 1){\n    vp.pos <- c(vp.pos,vp.pos)\n  }\n  vp.pos <- sort(vp.pos)\n  data.m <- data[[1]]\n  for( i in 2:num.exp ){\n    data.m <- merge(data.m, data[[i]], by=1)\n  }\n  #create the background model for the upstream regions\n  data.bg <- data.m\n  for( i in 1:num.exp ){\n    data.bg[data.m[,1] < vp.pos[1],i+1] <- get.background(data.m[data.m[,1] < vp.pos[1],c(1,i+1)], vp.pos[1] )\n  }\n  #and for the downstream regions\n  for( i in 1:num.exp ){\n    data.bg[data.m[,1] > vp.pos[2],i+1] <- get.background(data.m[data.m[,1] > vp.pos[2],c(1,i+1)], vp.pos[2] )\n  }\n  #if two viewpoint fragments are given set the intervening fragments\n  #to zero\n  #set background to 1 to prevent NaN in the ratio\n  if(vp.pos[1] != vp.pos[2]){\n    for( i in 1:num.exp){\n      data.m[data.m[,1] >= vp.pos[1] & data.m[,1] <= vp.pos[2],i+1] <- 0\n      data.bg[data.m[,1] >= vp.pos[1] & data.m[,1] <= vp.pos[2],i] <- 1\n    }\n  }\n  cbind(data.m, data.bg[,-1])\n}\n\n#perform pava regression and return the background regression line\nget.background <- function( data, vp.pos, weight.factor=0, fractile=F){\n  require(isotone)\n  switched = FALSE\n  weights <- (1:nrow(data))**weight.factor\n  if(data[1,1] > vp.pos){\n    data[,1] <- -data[,1] #reverse the sign to make the trend increasing\n    switched = TRUE\n    weights <- rev(weights)\n  }\n  #create the isotonic regression\n  if(fractile){\n    lm <- gpava(data[,1], data[,2], solver=weighted.fractile, weights=NULL, p=0.75)\n  }else{\n    lm <- gpava(data[,1], data[,2], solver=weighted.mean)\n  }\n\n  if(switched)\n    pred.data <- data.frame( -lm$z, lm$x )\n  else\n    pred.data <- data.frame( lm$z, lm$x )\n\n  pred.data[order(pred.data[,1]),2]\n}\n\nget.single.background <- function(data, num.exp = 1, vp.pos) {\n\n  if (length(vp.pos) == 1) {\n    vp.pos <- c(vp.pos, vp.pos)\n  }\n  vp.pos <- sort(vp.pos)\n\n  data.bg <- data\n  data.bg[data[, 1] < vp.pos[1], 2] <- get.background(data[data[, 1] < vp.pos[1], c(1, 2)], vp.pos[1])\n  data.bg[data[, 1] > vp.pos[2], 2] <- get.background(data[data[, 1] > vp.pos[2], c(1, 2)], vp.pos[2])\n\n  return(cbind(data, data.bg[, -1]))\n\n}\n\n\n\n\n##################################################################\n#General functions\n##################################################################\n\n#running mean function\n#' Title\n#'\n#' @param x numeric vector\n#' @param n window size for the running window\n#'\n#' @return a numeric vector with the windowed means\n#' @export\n#'\n#' @examples\nrunning<-function(x,n=20){\n  cumsum(x)->sum.v\n  sum.v<-c(0,sum.v)\n  #(sum.v[(n+1):length(x)]-sum.v[1:(length(x)-n)])/n\n  diff(sum.v,n)/n\n}\n\n#running sum\nrunsum<-function(x,n=20){\n  cumsum(x)->sum.v\n  sum.v<-c(0,sum.v)\n  diff(sum.v,n)\n}\n\n#make running function compatible vector\n#' Remove leading and trailing values\n#'\n#' @param a vector\n#' @param n window size of the corresponding running function\n#' @description remove n/2 elements from the front and the end\n#' @return vector, shortened by (n - 1) elements\n#' @export\n#'\n#' @examples\nrem <- function(a, n ){\n  half.window <- floor(n/2)\n  head(tail(a, -half.window),-half.window)\n}\n\n#quick way of generating a vector with the required indexes\nmulti.seq <- function( start, end ){\n  x <- rep(start, end-start+1)->x\n  df <- diff(x)\n  df <- df + 1\n  low <- which(df > 1)\n  df[low] <- -diff(c(0,low))+1\n  add <- c(0,cumsum(df))\n  x + add\n}\n\n#wrapper function to calculate the quantile distribution of all\n#non-zero values\nnon.zero.quantile <- function( x, probs ){\n  quantile(x[x > 0], probs)\n}\n\n\n",
    "created" : 1489585485107.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3233609055",
    "id" : "493EA3DC",
    "lastKnownWriteTime" : 1508158242,
    "path" : "~/development/R/packages/peakC/R/util_functions.R",
    "project_path" : "R/util_functions.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_source"
}